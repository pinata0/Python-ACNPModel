---
생성자: Pinata
생성 일시: Invalid date
Resource: https://hanyang.dcollection.net/public_resource/pdf/200000486149_20250212172211.pdf
상위 문서:
  - "[[Policy Gradient Algorithm]]"
---
**MDP (Marcov Decision Process)**

- **마르코프 결정 과정**

순차적 단계를 가진 의사 결정 과정을 모델링하기 위한 수학적 모형

  

- S : 에이전트가 인식하는 상태의 집합
- A : 에어전트가 취할 수 있는 모든 행동의 집합
- P : 상태 전이 확률 함수
- R : 보상 함수
- γ : 할인인자

  

어떤 시점에 어떤 **상태 S**에 존재한다면.  
에이전트는 **행동 A**를 취할 수 있고,  
**확률적**으로 새로운 **상태 S’**로 전이하게 된다.

  
에이전트는 상태 전이에 따른 **보상**을 받는다.  
(**새로운 상태로 전이하는 확률**은 에이전트의 행동에 영향을 받는다.)

  
즉, 다음 상태 S’은 현재 상태 S와 행동 A에만 영향을 받고,  
**이전 상태와는 독립적**일 때에 마르코프 속성을 만족하게 된다.